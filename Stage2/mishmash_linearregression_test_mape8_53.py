# -*- coding: utf-8 -*-
"""Mishmash_linearregression_test_mape8.53.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NxcJ8-kPBjfXNMc-PZYrQ8jzLrKNjRDm
"""

from google.colab import drive
drive.mount('/content/drive/')

cd /content/drive/My\ Drive/O2P_21Nov/mishmash/Unilever

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import  make_scorer 
import numpy as np
from random import randint
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score 
from sklearn.preprocessing import MinMaxScaler
import math 

import lightgbm as lgb 

#As this is day wise data aggreting on 28 days for getting period #
tr=pd.read_excel('TrainingData.xlsx')
df=tr.copy()

def fun1(str1):
    return(str1.split(' - ')[0])

def fun2(str1):
    return(str1.split(':')[1]) 

df['Year']=df['Period'].apply(fun1)
df['Period']=df['Period'].apply(fun2)
df['Year']=df['Year'].astype('int32')
df['Period']=df['Period'].astype('int32')

tr=df.copy()


te=pd.read_excel('TestData.xlsx')

def fun1(str1):
    return(str1.split(' - ')[0])

def fun2(str1):
    return(str1.split(':')[1]) 

te['Year']=te['Period'].apply(fun1)
te['Period']=te['Period'].apply(fun2)



def mape(y_true, y_pred):
  import pandas as pd
  if pd.Series(pd.Series(y_true)==0).any(): return np.inf
  else:
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100


df=pd.concat([tr,te])
df.columns
#df['Period']=df['Period'].astype('int32')
#df['Year']=df['Year'].astype('int32')


def smape(y_true, y_pred):
  y_true, y_pred = np.array(y_true), np.array(y_pred)
  y_true[y_true==0] = 1e-3
  y_pred[y_pred==0] = 1e-3
  
  return np.mean(np.abs(y_true - y_pred)/(np.abs(y_true) + np.abs(y_pred))) *100


def wrmse(y_true, y_pred):
  import pandas as pd
  from sklearn.metrics import mean_squared_error as mse
  wt=np.array([np.float64(0)]*len(y_true))
  #print('wrmse')
  for i in range(0,len(y_true)):
      #print(i)
      try:wt[i]=np.exp(-1/(int((len(y_true)-i)/3)))
    #  try:wt[i]=np.power(1/int((np.power(len(y_true)-i,1.1)/2)),1/2)
      except: wt[i]=np.exp(0)
      #print(wt[i])
  return np.sqrt(mse(np.asarray(y_true),np.asarray(y_pred),sample_weight=wt))

columns = [
 'Social_Search_Impressions',
 'Social_Search_Working_cost',
 'Digital_Impressions',
 'Digital_Working_cost',
 'Print_Impressions.Ads40',
 'Print_Working_Cost.Ads50',
 'OOH_Impressions',
 'OOH_Working_Cost',
 'SOS_pct',
 'Digital_Impressions_pct',
 'CCFOT',
 'Median_Temp',
 'Median_Rainfall',
 'Fuel_Price',
 'Inflation',
 'Trade_Invest',
 'Brand_Equity',
 'Avg_EQ_Price',
 'Any_Promo_pct_ACV',
 'Any_Feat_pct_ACV',
 'Any_Disp_pct_ACV',
 'EQ_Base_Price',
 'Est_ACV_Selling',
 'pct_ACV',
 'Avg_no_of_Items',
 'pct_PromoMarketDollars_Category',
 'RPI_Category',
 'Magazine_Impressions_pct',
 'TV_GRP',
 'Competitor1_RPI',
 'Competitor2_RPI',
 'Competitor3_RPI',
 'Competitor4_RPI',
 'EQ_Category',
 'EQ_Subcategory',
 'pct_PromoMarketDollars_Subcategory',
 'RPI_Subcategory']
for i in columns:
 tr[i] = tr[i].fillna((tr[i].mean()))

for i in columns:
 te[i] = te[i].fillna((te[i].mean()))

#Training model

import sklearn
from datetime import datetime
from sklearn.linear_model import Ridge 
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error as mse

y_actual=[]; y_pred=[]; rmse = []; map_error=[]


scaler = StandardScaler()
    
Y_train = tr['EQ'].values
X_train = tr.iloc[:,2:] 
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(te.iloc[:,2:])

ridgeparamlist = [0,0.001,0.01,0.1,1,2,5,8,10,20,50,80,100,1000,10000]
rmselist = []
rmselist_fullwindow = []

y_predict_list = []
for ridgeparam in ridgeparamlist:
    kf = KFold(n_splits=10)
    y_predict = []
    for train_index, valid_index in kf.split(X_train):
        X_train1, X_valid1 = X_train[train_index,:], X_train[valid_index,:]
        Y_train1 = Y_train[train_index,]
        reg = Ridge(alpha=ridgeparam)
        reg.fit(X_train1, Y_train1)
        y_predict = y_predict + list(reg.predict(X_valid1))

    rmselist.append(mape(Y_train[-3*3:],y_predict[-3*3:]))  
    rmselist_fullwindow.append(mape(Y_train,y_predict))  
    y_predict_list.append(y_predict)

n_splits = 3
validation_window = 3
best_ridge_param = ridgeparamlist[np.array(rmselist_fullwindow).argmin()]
y_predict = y_predict_list[np.array(rmselist_fullwindow).argmin()]

predictions = y_predict[-n_splits*validation_window:]

forecast1=pd.concat([pd.Series(tr.index[-n_splits*validation_window:]),pd.Series(predictions), pd.Series(['linearregression_mv']*n_splits*validation_window)],axis=1)
forecast1.columns=['Period','EQ','method']

reg1 = Ridge(alpha=best_ridge_param)
reg1.fit(X_train, Y_train)

forecast2=pd.concat([pd.Series(te.index),pd.Series(reg1.predict(X_test)),pd.Series(['linearregression_mv']*5)],axis=1)
forecast2.columns=['Period','EQ','method']  
forecast2

te

val_accuracy={'mape': rmselist[np.array(rmselist_fullwindow).argmin()]}
val_accuracy

#finding Test Accuracy

mapelist = []
mapelist_fullwindow = []
fore_y_list = []

test_y = te.iloc[:,1]
fore_y = forecast2.iloc[:,1]

mapelist.append(smape(test_y,fore_y))  
mapelist_fullwindow.append(smape(test_y,fore_y))  
fore_y_list.append(fore_y)

test_accuracy={'mape': mapelist[np.array(mapelist_fullwindow).argmin()]}
test_accuracy

#Finding correlation

corr = tr.corr()
variables = (corr.iloc[1,:]).to_list()

columns = ['EQ','Social_Search_Impressions',
       'Social_Search_Working_cost', 'Digital_Impressions',
       'Digital_Working_cost', 'Print_Impressions.Ads40',
       'Print_Working_Cost.Ads50', 'OOH_Impressions', 'OOH_Working_Cost',
       'SOS_pct', 'Digital_Impressions_pct', 'CCFOT', 'Median_Temp',
       'Median_Rainfall', 'Fuel_Price', 'Inflation', 'Trade_Invest',
       'Brand_Equity', 'Avg_EQ_Price', 'Any_Promo_pct_ACV', 'Any_Feat_pct_ACV',
       'Any_Disp_pct_ACV', 'EQ_Base_Price', 'Est_ACV_Selling', 'pct_ACV',
       'Avg_no_of_Items', 'pct_PromoMarketDollars_Category', 'RPI_Category',
       'Magazine_Impressions_pct', 'TV_GRP', 'Competitor1_RPI',
       'Competitor2_RPI', 'Competitor3_RPI', 'Competitor4_RPI', 'EQ_Category',
       'EQ_Subcategory', 'pct_PromoMarketDollars_Subcategory',
       'RPI_Subcategory', 'Year']

variables[1:]

plot_data = pd.DataFrame()
plot_data['Columns']=columns
plot_data['Value']=variables[1:]

plot_data = plot_data[plot_data['Value']>0.4]

import matplotlib.pyplot as plt
fig = plt.figure(figsize=(15,5))
ax = fig.add_axes([0,0,1,1])
langs =plot_data['Columns'].to_list()
students = plot_data['Value'].to_list()
ax.bar(langs,students)
plt.show()